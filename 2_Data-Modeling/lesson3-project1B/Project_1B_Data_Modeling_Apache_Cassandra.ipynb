{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Data Modeling - Project 1B\n",
    "# Data Modeling with Apache Cassandra\n",
    "\n",
    "## 1. Introduction\n",
    "A startup called Sparkify wants to analyze the data they've been collecting on songs and user activity on their new music streaming app. The analysis team is particularly interested in understanding what songs users are listening to. Currently, there is no easy way to query the data to generate the results, since the data reside in a directory of CSV files on user activity on the app.\n",
    "\n",
    "They'd like a data engineer to create an Apache Cassandra database which can create queries on song play data to answer the questions, and wish to bring you on the project. My role is to create a database for this analysis. I'll be able to test my database by running queries given to me by the analytics team from Sparkify to create the results.\n",
    "\n",
    "### 1.1 Project Overview\n",
    "In this project, I'll apply what I've learned on data modeling with Apache Cassandra and complete an ETL pipeline using Python. To complete the project, I will need to model my data by creating tables in Apache Cassandra to run queries. I am provided with part of the ETL pipeline that transfers data from a set of CSV files within a directory to create a streamlined CSV file to model and insert data into Apache Cassandra tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## 2. ETL Pipeline for Pre-Processing the Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 2.1 Import Python packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Import Python packages \n",
    "import pandas as pd\n",
    "import cassandra\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 2.2 Creating list of filepaths to process original event csv data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current working directory: /home/workspace\n",
      "30 files found in /home/workspace/event_data\n"
     ]
    }
   ],
   "source": [
    "# checking the current working directory\n",
    "print('current working directory: ' + os.getcwd())\n",
    "\n",
    "# Get the current folder and subfolder event data\n",
    "filepath = os.getcwd() + '/event_data'\n",
    "\n",
    "# create a list of files and collect each filepath\n",
    "for root, dirs, files in os.walk(filepath):\n",
    "# join the file path and roots with the subdirectories using glob\n",
    "    file_path_list = glob.glob(os.path.join(root,'*'))\n",
    "    print('%s files found in %s' % (len(file_path_list), filepath))\n",
    "    # DEBUG: print list of files\n",
    "#    for item in file_path_list:\n",
    "#        print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 2.3 Processing the files to create the data file csv that will be used for Apache Casssandra tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data added to full_data_rows_list from: /home/workspace/event_data/2018-11-30-events.csv\n",
      "Data added to full_data_rows_list from: /home/workspace/event_data/2018-11-23-events.csv\n",
      "Data added to full_data_rows_list from: /home/workspace/event_data/2018-11-22-events.csv\n",
      "Data added to full_data_rows_list from: /home/workspace/event_data/2018-11-29-events.csv\n",
      "Data added to full_data_rows_list from: /home/workspace/event_data/2018-11-11-events.csv\n",
      "Data added to full_data_rows_list from: /home/workspace/event_data/2018-11-14-events.csv\n",
      "Data added to full_data_rows_list from: /home/workspace/event_data/2018-11-20-events.csv\n",
      "Data added to full_data_rows_list from: /home/workspace/event_data/2018-11-15-events.csv\n",
      "Data added to full_data_rows_list from: /home/workspace/event_data/2018-11-05-events.csv\n",
      "Data added to full_data_rows_list from: /home/workspace/event_data/2018-11-28-events.csv\n",
      "Data added to full_data_rows_list from: /home/workspace/event_data/2018-11-25-events.csv\n",
      "Data added to full_data_rows_list from: /home/workspace/event_data/2018-11-16-events.csv\n",
      "Data added to full_data_rows_list from: /home/workspace/event_data/2018-11-18-events.csv\n",
      "Data added to full_data_rows_list from: /home/workspace/event_data/2018-11-24-events.csv\n",
      "Data added to full_data_rows_list from: /home/workspace/event_data/2018-11-04-events.csv\n",
      "Data added to full_data_rows_list from: /home/workspace/event_data/2018-11-19-events.csv\n",
      "Data added to full_data_rows_list from: /home/workspace/event_data/2018-11-26-events.csv\n",
      "Data added to full_data_rows_list from: /home/workspace/event_data/2018-11-12-events.csv\n",
      "Data added to full_data_rows_list from: /home/workspace/event_data/2018-11-27-events.csv\n",
      "Data added to full_data_rows_list from: /home/workspace/event_data/2018-11-06-events.csv\n",
      "Data added to full_data_rows_list from: /home/workspace/event_data/2018-11-09-events.csv\n",
      "Data added to full_data_rows_list from: /home/workspace/event_data/2018-11-03-events.csv\n",
      "Data added to full_data_rows_list from: /home/workspace/event_data/2018-11-21-events.csv\n",
      "Data added to full_data_rows_list from: /home/workspace/event_data/2018-11-07-events.csv\n",
      "Data added to full_data_rows_list from: /home/workspace/event_data/2018-11-01-events.csv\n",
      "Data added to full_data_rows_list from: /home/workspace/event_data/2018-11-13-events.csv\n",
      "Data added to full_data_rows_list from: /home/workspace/event_data/2018-11-17-events.csv\n",
      "Data added to full_data_rows_list from: /home/workspace/event_data/2018-11-08-events.csv\n",
      "Data added to full_data_rows_list from: /home/workspace/event_data/2018-11-10-events.csv\n",
      "Data added to full_data_rows_list from: /home/workspace/event_data/2018-11-02-events.csv\n"
     ]
    }
   ],
   "source": [
    "# initiating an empty list of rows that will be generated from each file\n",
    "full_data_rows_list = [] \n",
    "    \n",
    "# for every filepath in the file path list \n",
    "for f in file_path_list:\n",
    "\n",
    "# reading csv file \n",
    "    with open(f, 'r', encoding = 'utf8', newline='') as csvfile: \n",
    "        # creating a csv reader object \n",
    "        csvreader = csv.reader(csvfile)\n",
    "        # skip column names\n",
    "        next(csvreader)\n",
    "        \n",
    " # extracting each data row one by one and append it        \n",
    "        for line in csvreader:\n",
    "            #DEBUG: print every line of raw data\n",
    "#            print(line)\n",
    "            full_data_rows_list.append(line)\n",
    "        print('Data added to full_data_rows_list from: %s' % f)\n",
    "            \n",
    "# DEBUG: get total number of rows\n",
    "# print(len(full_data_rows_list))\n",
    "# DEBUG: see what the list of event data rows will look like\n",
    "#for number, row in enumerate(full_data_rows_list):\n",
    "#    if row[0] != '':\n",
    "#        print(number, row)\n",
    "\n",
    "# creating a smaller event data csv file called event_datafile_full csv that will be used to insert data into the \\\n",
    "# Apache Cassandra tables\n",
    "csv.register_dialect('myDialect', quoting=csv.QUOTE_ALL, skipinitialspace=True)\n",
    "\n",
    "i = 0\n",
    "with open('event_datafile_new.csv', 'w', encoding = 'utf8', newline='') as f:\n",
    "    writer = csv.writer(f, dialect='myDialect')\n",
    "    writer.writerow(['artist','firstName','gender','itemInSession','lastName','length',\\\n",
    "                'level','location','sessionId','song','userId'])\n",
    "    for row in full_data_rows_list:\n",
    "        if (row[0] == ''):\n",
    "            continue\n",
    "        writer.writerow((row[0], row[2], row[3], row[4], row[5], row[6], row[7], row[8], row[12], row[13], row[16]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in new csv file: 6821\n"
     ]
    }
   ],
   "source": [
    "# check the number of rows in your csv file\n",
    "with open('event_datafile_new.csv', 'r', encoding = 'utf8') as f:\n",
    "    print('Number of rows in new csv file: %s' % sum(1 for line in f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>firstName</th>\n",
       "      <th>gender</th>\n",
       "      <th>itemInSession</th>\n",
       "      <th>lastName</th>\n",
       "      <th>length</th>\n",
       "      <th>level</th>\n",
       "      <th>location</th>\n",
       "      <th>sessionId</th>\n",
       "      <th>song</th>\n",
       "      <th>userId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stephen Lynch</td>\n",
       "      <td>Jayden</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>Bell</td>\n",
       "      <td>182.85669</td>\n",
       "      <td>free</td>\n",
       "      <td>Dallas-Fort Worth-Arlington, TX</td>\n",
       "      <td>829</td>\n",
       "      <td>Jim Henson's Dead</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Manowar</td>\n",
       "      <td>Jacob</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>Klein</td>\n",
       "      <td>247.56200</td>\n",
       "      <td>paid</td>\n",
       "      <td>Tampa-St. Petersburg-Clearwater, FL</td>\n",
       "      <td>1049</td>\n",
       "      <td>Shell Shock</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Morcheeba</td>\n",
       "      <td>Jacob</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>Klein</td>\n",
       "      <td>257.41016</td>\n",
       "      <td>paid</td>\n",
       "      <td>Tampa-St. Petersburg-Clearwater, FL</td>\n",
       "      <td>1049</td>\n",
       "      <td>Women Lose Weight (Feat: Slick Rick)</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>Jacob</td>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "      <td>Klein</td>\n",
       "      <td>231.23546</td>\n",
       "      <td>paid</td>\n",
       "      <td>Tampa-St. Petersburg-Clearwater, FL</td>\n",
       "      <td>1049</td>\n",
       "      <td>Won't Go Home Without You</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Train</td>\n",
       "      <td>Jacob</td>\n",
       "      <td>M</td>\n",
       "      <td>3</td>\n",
       "      <td>Klein</td>\n",
       "      <td>216.76363</td>\n",
       "      <td>paid</td>\n",
       "      <td>Tampa-St. Petersburg-Clearwater, FL</td>\n",
       "      <td>1049</td>\n",
       "      <td>Hey_ Soul Sister</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          artist firstName gender  itemInSession lastName     length level  \\\n",
       "0  Stephen Lynch    Jayden      M              0     Bell  182.85669  free   \n",
       "1        Manowar     Jacob      M              0    Klein  247.56200  paid   \n",
       "2      Morcheeba     Jacob      M              1    Klein  257.41016  paid   \n",
       "3       Maroon 5     Jacob      M              2    Klein  231.23546  paid   \n",
       "4          Train     Jacob      M              3    Klein  216.76363  paid   \n",
       "\n",
       "                              location  sessionId  \\\n",
       "0      Dallas-Fort Worth-Arlington, TX        829   \n",
       "1  Tampa-St. Petersburg-Clearwater, FL       1049   \n",
       "2  Tampa-St. Petersburg-Clearwater, FL       1049   \n",
       "3  Tampa-St. Petersburg-Clearwater, FL       1049   \n",
       "4  Tampa-St. Petersburg-Clearwater, FL       1049   \n",
       "\n",
       "                                   song  userId  \n",
       "0                     Jim Henson's Dead      91  \n",
       "1                           Shell Shock      73  \n",
       "2  Women Lose Weight (Feat: Slick Rick)      73  \n",
       "3             Won't Go Home Without You      73  \n",
       "4                      Hey_ Soul Sister      73  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show head of datafile\n",
    "df = pd.read_csv('event_datafile_new.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## 3. Build up an Apache Cassandra database and do some queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 3.1 Creating a Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create a connection to a Cassandra instance your local machine \n",
    "# (127.0.0.1)\n",
    "\n",
    "from cassandra.cluster import Cluster\n",
    "cluster = Cluster()\n",
    "\n",
    "# Create a session to establish connection and begin executing queries\n",
    "session = cluster.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 3.2 Create Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    session.execute(\"\"\"\n",
    "    CREATE KEYSPACE IF NOT EXISTS music_app \n",
    "    WITH REPLICATION = \n",
    "    { 'class' : 'SimpleStrategy', 'replication_factor' : 1 }\"\"\"\n",
    ")\n",
    "\n",
    "except Exception as e:\n",
    "    print(e) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 3.3 Set Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    session.set_keyspace('music_app')\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 3.4 Create tables in database for the given queries\n",
    "Using NoSQL databases like Apache Cassandra means that you are not allowed to JOIN between different tables and that denormalization is a must. One table per query is a common strategy and so you have to come from the queries first.\n",
    "\n",
    "The following queries are commonly used in our business case:\n",
    "\n",
    "1. Give me the **artist**, **song title** and **song's length** in the music app history that was heard during **sessionId = 338** and **itemInSession = 4**\n",
    "2. Give me only the following: **name of artist**, **song (sorted by itemInSession)** and **user (first and last name)** for **userid = 10, sessionid = 182**\n",
    "3. Give me every **user name (first and last)** in my music app history who listened to the **song 'All Hands Against His Own'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# function to create a table in Apache Cassandra\n",
    "def create_table(session, table_name, columns_with_datatype, primary_key):\n",
    "    query = f\"CREATE TABLE IF NOT EXISTS {table_name} ({columns_with_datatype}, PRIMARY KEY ({primary_key}));\"\n",
    "    print(query)\n",
    "    try:\n",
    "        session.execute(query)\n",
    "        print('Table <%s> created successfully' % table_name)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# function to import data in a table in Apache Cassandra\n",
    "def import_data(session, table_name, file, columns):\n",
    "    # show query\n",
    "    #print(f\"INSERT INTO {table_name} ({columns}) VALUES ({values});\")\n",
    "    # read csv file with the data in pandas dataframe\n",
    "    try:\n",
    "        file_data = pd.read_csv(file, usecols=columns, encoding='utf8')\n",
    "        print('<%s> opened successfully' % file)\n",
    "        print('Insert data ...')\n",
    "        # import data in database line by line\n",
    "        for index, line in file_data.iterrows():\n",
    "            vals = []\n",
    "            for col in columns:\n",
    "                # extract values from line and replace single quotes in strings\n",
    "                try:\n",
    "                    val = line[col].replace(\"'\",\"\")\n",
    "                except:\n",
    "                    val = line[col]\n",
    "                vals.append(val)\n",
    "            query = f\"INSERT INTO {table_name} ({', '.join(columns)}) VALUES {tuple(vals)};\"\n",
    "            # insert data from the csv into the table\n",
    "            session.execute(query)\n",
    "        print('Data inserted successfully')\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def query_data(session, table_name, select_parameters, where_string):\n",
    "    query = f\"SELECT {', '.join(select_parameters)} FROM {table_name} WHERE {where_string}\"\n",
    "    # show query\n",
    "    print(query)\n",
    "    try:\n",
    "        rows = session.execute(query)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    # show dataframe with solution of query \n",
    "    df = pd.DataFrame(list(rows))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 3.4.1 Query 1: *Give me the artist, song title and song's length in the music app history that was heard during sessionId = 338 and itemInSession = 4*\n",
    "Create a table only with the mentioned parameters. The look-up parameters in the second part can be used as a compound primary key because they are unique for the given dataset.\n",
    "##### 3.4.1.1 Create table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# define table_name, columns with dataypes and primary key\n",
    "table_name = 'songInfo'\n",
    "columns_with_datatype = 'sessionId int, itemInSession int, artist text, song text, length float'\n",
    "primary_key = 'sessionId, itemInSession'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE TABLE IF NOT EXISTS songInfo (sessionId int, itemInSession int, artist text, song text, length float, PRIMARY KEY (sessionId, itemInSession));\n",
      "Table <songInfo> created successfully\n"
     ]
    }
   ],
   "source": [
    "# create table with the predefined parameters\n",
    "create_table(session, table_name, columns_with_datatype, primary_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 3.4.1.2 Import parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# define import parameters\n",
    "file = 'event_datafile_new.csv'\n",
    "columns = ['sessionId', 'itemInSession', 'artist', 'song', 'length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<event_datafile_new.csv> opened successfully\n",
      "Insert data ...\n",
      "Data inserted successfully\n"
     ]
    }
   ],
   "source": [
    "# import data with the predefined parameters\n",
    "import_data(session, table_name, file, columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 3.4.1.3 Make query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# define query parameters\n",
    "select_parameters = ['artist', 'song', 'length']\n",
    "where_string = 'sessionId = 338 AND itemInSession = 4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT artist, song, length FROM songInfo WHERE sessionId = 338 AND itemInSession = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Faithless</td>\n",
       "      <td>Music Matters (Mark Knight Dub)</td>\n",
       "      <td>495.307312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      artist                             song      length\n",
       "0  Faithless  Music Matters (Mark Knight Dub)  495.307312"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make query with the predefined parameters\n",
    "query_data(session, table_name, select_parameters, where_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 3.4.2 Query 2: *Give me only the following: name of artist, song (sorted by itemInSession) and user (first and last name) for userid = 10, sessionid = 182*\n",
    "Create a table only with the mentioned parameters. The parameters in the WHERE clause can be used as a compound primary key with userId and sessionId because they are unique for the given dataset. In addition itemInSession is added as clustering key for sorting.\n",
    "##### 3.4.2.1 Create table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# define table_name, columns with dataypes and primary key\n",
    "table_name = 'sessionInfo'\n",
    "columns_with_datatype = 'userId int, sessionId int, itemInSession int, artist text, song text, firstName text, lastName text'\n",
    "primary_key = '(userId, sessionId), itemInSession'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE TABLE IF NOT EXISTS sessionInfo (userId int, sessionId int, itemInSession int, artist text, song text, firstName text, lastName text, PRIMARY KEY ((userId, sessionId), itemInSession));\n",
      "Table <sessionInfo> created successfully\n"
     ]
    }
   ],
   "source": [
    "# create table with the predefined parameters\n",
    "create_table(session, table_name, columns_with_datatype, primary_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 3.4.2.2 Import parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# define import parameters\n",
    "file = 'event_datafile_new.csv'\n",
    "columns = ['userId', 'sessionId', 'itemInSession', 'artist', 'song', 'firstName', 'lastName']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<event_datafile_new.csv> opened successfully\n",
      "Insert data ...\n",
      "Data inserted successfully\n"
     ]
    }
   ],
   "source": [
    "# import data with the predefined parameters\n",
    "import_data(session, table_name, file, columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 3.4.2.3 Make query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# define query parameters\n",
    "select_string = ['artist', 'song', 'firstName', 'lastName']\n",
    "where_string = 'userId = 10 AND sessionId = 182'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT artist, song, firstName, lastName FROM sessionInfo WHERE userId = 10 AND sessionId = 182\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>firstname</th>\n",
       "      <th>lastname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Down To The Bone</td>\n",
       "      <td>Keep On Keepin On</td>\n",
       "      <td>Sylvie</td>\n",
       "      <td>Cruz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Three Drives</td>\n",
       "      <td>Greece 2000</td>\n",
       "      <td>Sylvie</td>\n",
       "      <td>Cruz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sebastien Tellier</td>\n",
       "      <td>Kilometer</td>\n",
       "      <td>Sylvie</td>\n",
       "      <td>Cruz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lonnie Gordon</td>\n",
       "      <td>Catch You Baby (Steve Pitron &amp; Max Sanna Radio...</td>\n",
       "      <td>Sylvie</td>\n",
       "      <td>Cruz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              artist                                               song  \\\n",
       "0   Down To The Bone                                  Keep On Keepin On   \n",
       "1       Three Drives                                        Greece 2000   \n",
       "2  Sebastien Tellier                                          Kilometer   \n",
       "3      Lonnie Gordon  Catch You Baby (Steve Pitron & Max Sanna Radio...   \n",
       "\n",
       "  firstname lastname  \n",
       "0    Sylvie     Cruz  \n",
       "1    Sylvie     Cruz  \n",
       "2    Sylvie     Cruz  \n",
       "3    Sylvie     Cruz  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make query with the predefined parameters\n",
    "query_data(session, table_name, select_string, where_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 3.4.3 Query 3: *Give me every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'*\n",
    "Create a table with the mentioned parameters and additional parameters in order to get a unique primary key. I'll use userId because it's the best parameter to seperate users.\n",
    "##### 3.4.3.1 Create table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# define table_name, columns with dataypes and primary key\n",
    "table_name = 'userInfo'\n",
    "columns_with_datatype = 'song text, userId int, firstName text, lastName text'\n",
    "primary_key = 'song, userId'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE TABLE IF NOT EXISTS userInfo (song text, userId int, firstName text, lastName text, PRIMARY KEY (song, userId));\n",
      "Table <userInfo> created successfully\n"
     ]
    }
   ],
   "source": [
    "# create table with the predefined parameters\n",
    "create_table(session, table_name, columns_with_datatype, primary_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 3.4.3.2 Import parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# define import parameters\n",
    "file = 'event_datafile_new.csv'\n",
    "columns = ['song', 'userId', 'firstName', 'lastName']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<event_datafile_new.csv> opened successfully\n",
      "Insert data ...\n",
      "Data inserted successfully\n"
     ]
    }
   ],
   "source": [
    "# import data with the predefined parameters\n",
    "import_data(session, table_name, file, columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 3.4.3.3 Make query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# define query parameters\n",
    "select_string = ['song', 'firstName', 'lastName']\n",
    "where_string = \"song = 'All Hands Against His Own'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT song, firstName, lastName FROM userInfo WHERE song = 'All Hands Against His Own'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song</th>\n",
       "      <th>firstname</th>\n",
       "      <th>lastname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>All Hands Against His Own</td>\n",
       "      <td>Jacqueline</td>\n",
       "      <td>Lynch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>All Hands Against His Own</td>\n",
       "      <td>Tegan</td>\n",
       "      <td>Levine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All Hands Against His Own</td>\n",
       "      <td>Sara</td>\n",
       "      <td>Johnson</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        song   firstname lastname\n",
       "0  All Hands Against His Own  Jacqueline    Lynch\n",
       "1  All Hands Against His Own       Tegan   Levine\n",
       "2  All Hands Against His Own        Sara  Johnson"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make query with the predefined parameters\n",
    "query_data(session, table_name, select_string, where_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Drop the tables before closing out the sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "songInfo dropped\n",
      "sessionInfo dropped\n",
      "userInfo dropped\n"
     ]
    }
   ],
   "source": [
    "# list of used tables\n",
    "tables = ['songInfo', 'sessionInfo', 'userInfo']\n",
    "\n",
    "# drop all tables in defined list\n",
    "for table in tables:\n",
    "    query = f\"DROP TABLE IF EXISTS {table}\"\n",
    "    try:\n",
    "        rows = session.execute(query)\n",
    "        print(f\"{table} dropped\")\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Close the session and cluster connection¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "session.shutdown()\n",
    "cluster.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
